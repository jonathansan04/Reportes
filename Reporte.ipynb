{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reporte.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHy+Cg+14mjdj+VTtDm1sF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonathansan04/Reportes/blob/master/Reporte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fNHmrqK611",
        "colab_type": "code",
        "outputId": "ae11fb4a-6cd8-4d10-dcd2-f1448601ff71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\t\n",
        "import sklearn \n",
        "from sklearn import datasets\n",
        "iris=sklearn.datasets.load_iris()\n",
        "print(\"Printing some sample data from the iris dataset\")\n",
        "for training_sample in list(zip(iris.data,iris.target))[:5]:\n",
        "    print(training_sample)\n",
        "features=iris.data \n",
        "iris_class=iris.target \n",
        "print(\"Splitting the data into testing and training samples\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test,iris_class_train, iris_class_test = train_test_split(features,iris_class, test_size=0.33, random_state=42)\n",
        "print(\"Data preprocessing\")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(features_train)\n",
        "features_train_scale = scaler.transform(features_train)\n",
        "features_test_scale = scaler.transform(features_test)\n",
        "\n",
        "#Realizamos la clasificacion para iris con una sola iteracion \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "iterations1=1   \n",
        "hidden_layers=[10,10,10]  \n",
        " \n",
        "mlp1 = MLPClassifier(hidden_layer_sizes=(hidden_layers), max_iter=iterations1) \n",
        "mlp1.fit(features_train_scale, iris_class_train) \n",
        "predicted1= mlp1.predict(features_test_scale)  \n",
        "print(\"Evaluation: considering the confusion matrix\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(iris_class_test,predicted1))  \n",
        "print(\"Evaluation report:\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(iris_class_test,predicted1)) \n",
        "\n",
        "#Realizamos la clasificacion para iris con una sola iteracion \n",
        "iterations=1000  \n",
        "hidden_layers=[10,10,10] \n",
        "mlp = MLPClassifier(hidden_layer_sizes=(hidden_layers), max_iter=iterations) \n",
        "mlp.fit(features_train_scale, iris_class_train) \n",
        "predicted = mlp.predict(features_test_scale)  \n",
        "print(\"Evaluation: considering the confusion matrix\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(iris_class_test,predicted))  \n",
        "print(\"Evaluation report:\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(iris_class_test,predicted)) \n",
        "\n",
        "#Realizamos la clasificacion para iris con una sola iteracion pero cambiando nuestra matriz hidden_layers a 1\n",
        "iterations1=1  \n",
        "hidden_layers1=[1,1,1] \n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=(hidden_layers1), max_iter=iterations1) \n",
        "mlp2.fit(features_train_scale, iris_class_train)  \n",
        "predicted2= mlp2.predict(features_test_scale) \n",
        "print(\"Evaluation: considering the confusion matrix\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(iris_class_test,predicted2))   \n",
        "print(\"Evaluation report:\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(iris_class_test,predicted2)) \n",
        "\n",
        "#la precisión es el número de resultados correctos dividido por el número de todos los resultados devueltos, la idea es mostrar este valor en favor de las muestras positivas en conclusion podemos ver como en el primer caso en comparacion tenemos una precision de 0.46 lo que nos dice que un poco \n",
        "#menos de la mitad del total de positivos, en el segundo caso vemos como encontramos una precision de uno lo que nos quiere decir que el resultado de positivos es el mismo a la cantidad,\n",
        "#en el ultimo ejemplo nos da 0 lo que quiere decir que no esta definida tp / (tp + fp)tpfp\n",
        "\n",
        "# la recuperación es el número de resultados correctos dividido por el número de resultados que deberían haberse devuelto, como sabemos en esta lo que encontramos es todas las  muestras\n",
        "#positivas tp / (tp + fn)tpfn, sabemos que si no encontramos valor o es un 0 esto es que este valor no esta definido\n",
        "\n",
        "#el f1 score se puede explicar de mejor manera como la media que existe entre la precision y el recuerdo donde el valor es entre 0 y 1 teniendo que 0 es el peor y uno el mejor,\n",
        "#como podemos ver en el segundo ejemplo la media armonica entre el recuerdo y la precision es demasiado alto\n",
        "\n",
        "#Los promedios informados incluyen el promedio mayor que es el promedio de la media no central por dato \n",
        "\n",
        "#El promedio ponderado es la media de tendencia central de los datos\n",
        "\n",
        "# El micro promedio es el promedio de todos los datos     \n",
        "\n",
        "#Como podemos ver en el primer y tercer ejemplo los promedios son muy bajos mientras que en el segundo ejemplo el promedio es muy alto\n",
        "\n",
        "#la columna support depende de la base de datos con la cual trabajamos, es la cantidad de valores para cada clasificacion "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Printing some sample data from the iris dataset\n",
            "(array([5.1, 3.5, 1.4, 0.2]), 0)\n",
            "(array([4.9, 3. , 1.4, 0.2]), 0)\n",
            "(array([4.7, 3.2, 1.3, 0.2]), 0)\n",
            "(array([4.6, 3.1, 1.5, 0.2]), 0)\n",
            "(array([5. , 3.6, 1.4, 0.2]), 0)\n",
            "Splitting the data into testing and training samples\n",
            "Data preprocessing\n",
            "Evaluation: considering the confusion matrix\n",
            "[[19  0  0]\n",
            " [15  0  0]\n",
            " [ 7  9  0]]\n",
            "Evaluation report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63        19\n",
            "           1       0.00      0.00      0.00        15\n",
            "           2       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.38        50\n",
            "   macro avg       0.15      0.33      0.21        50\n",
            "weighted avg       0.18      0.38      0.24        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Evaluation: considering the confusion matrix\n",
            "[[19  0  0]\n",
            " [ 0 15  0]\n",
            " [ 0  1 15]]\n",
            "Evaluation report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       0.94      1.00      0.97        15\n",
            "           2       1.00      0.94      0.97        16\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.98      0.98      0.98        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n",
            "Evaluation: considering the confusion matrix\n",
            "[[ 0 19  0]\n",
            " [ 0 15  0]\n",
            " [ 0 16  0]]\n",
            "Evaluation report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        19\n",
            "           1       0.30      1.00      0.46        15\n",
            "           2       0.00      0.00      0.00        16\n",
            "\n",
            "    accuracy                           0.30        50\n",
            "   macro avg       0.10      0.33      0.15        50\n",
            "weighted avg       0.09      0.30      0.14        50\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}